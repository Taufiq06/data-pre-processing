import urllib
import os
import zipfile
import pandas as pd
import cartosql


## USER INPUTS (you need to change these values)
# name of table on Carto where you want to upload data
# this should be a table name that is not currently in use
dataset_name = 'cli_029a_vulnerability_to_cc' #check

# set the directory that you are working in with the path variable
# you can use an environmental variable, as we did, or directly enter the directory name as a string
# example: path = '/home/cli_029a_vulnerability_to_cc'
dir = os.getenv('PROCESSING_DIR')+dataset_name

# insert the url used to download the data from the source website
SOURCE_URL='https://gain.nd.edu/assets/323406/resources_2019_19_01_21h59_1_1_.zip'  #check


## PROCESSING
#move to directory that we want to pull data into
os.chdir(dir)

# download the climate change vulnerability data from the source and unzip
data_file = 'data'
urllib.request.urlretrieve(SOURCE_URL, data_file+'.zip')
zip_ref = zipfile.ZipFile(data_file+'.zip', 'r')
zip_ref.extractall(data_file)
zip_ref.close()

#read in climate change vulnerability data to pandas dataframe
filename=data_file+'/resources/vulnerability/vulnerability.csv'
vulnerability_df=pd.read_csv(filename)

#read in climate change readiness data to pandas dataframe
filename=data_file+'/resources/readiness/readiness.csv'
readiness_df=pd.read_csv(filename)

#read in nd-gain score data to pandas dataframe
filename=data_file+'/resources/gain/gain.csv'
gain_df=pd.read_csv(filename)

#convert tables from wide form (each year is a column) to long form (a single column of years and a single column of values)
vulnerability_df_long = pd.melt(vulnerability_df,id_vars=['ISO3', 'Name'],var_name='year', value_name='vulnerability')
readiness_df_long = pd.melt(readiness_df,id_vars=['ISO3', 'Name'],var_name='year', value_name='readiness')
gain_df_long = pd.melt(gain_df,id_vars=['ISO3', 'Name'],var_name='year', value_name='gain')

#merge 3 indicators into one table
final_df = vulnerability_df_long.merge(readiness_df_long, left_on=['ISO3', 'Name', 'year'], right_on=['ISO3', 'Name', 'year']).merge(gain_df_long, left_on=['ISO3', 'Name', 'year'], right_on=['ISO3', 'Name', 'year'])

#convert year column from string to number
final_df.year=final_df.year.astype('int64')

#replace all NaN with None
final_df=final_df.where((pd.notnull(final_df)), None)

# UPLOAD
# specify column names and types
CARTO_SCHEMA ={'iso3': 'text', 'country': 'text', 'year': 'numeric', 'vulnerability': 'numeric', 'readiness': 'numeric', 'gain': 'numeric'}

# check if table exists
if cartosql.tableExists(dataset_name, user=os.getenv('CARTO_WRI_RW_USER'), key=os.getenv('CARTO_WRI_RW_KEY')):
    print('This table already exists. Please change the name and try again.')
else:
    # create table with appropriate columns
    cartosql.createTable(dataset_name, CARTO_SCHEMA, user=os.getenv('CARTO_WRI_RW_USER'), key=os.getenv('CARTO_WRI_RW_KEY'))
    # send processed data to table
    cartosql.blockInsertRows(dataset_name, CARTO_SCHEMA.keys(), CARTO_SCHEMA.values(), final_df.values.tolist(),
                             user=os.getenv('CARTO_WRI_RW_USER'), key=os.getenv('CARTO_WRI_RW_KEY'))
